{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"BERT_fakeNews_1021.ipynb","provenance":[{"file_id":"1XqAEi9XgRsQ_bz66JdiodkR191UCa89Z","timestamp":1603093710434}],"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.5"},"widgets":{"application/vnd.jupyter.widget-state+json":{"259f2aba28b74cf2af2bcf21268dbf04":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_f863e499927d4e0f88e79fdd47fa40e7","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_b2379f4ecc504838b417948ea68a3854","IPY_MODEL_20e2e2e370354c779fb91b024c954c8a"]}},"f863e499927d4e0f88e79fdd47fa40e7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"b2379f4ecc504838b417948ea68a3854":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_701083f864de40839bb8e15ce7cf0fbc","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":995526,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":995526,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_055acf729d304c34b7692ef4a8093ba0"}},"20e2e2e370354c779fb91b024c954c8a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_c872cc6a9a444cc89734e6c13d74d00d","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 996k/996k [00:00&lt;00:00, 5.28MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_79e02ffe4ce94bd8b9f4c943099578be"}},"701083f864de40839bb8e15ce7cf0fbc":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"055acf729d304c34b7692ef4a8093ba0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"c872cc6a9a444cc89734e6c13d74d00d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"79e02ffe4ce94bd8b9f4c943099578be":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"e4207e73745b442faa006566de58ce3b":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_4357c0a10c5f466f8f70e1aa1a71daab","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_010d6762488f4f539dea79135c6c4d8c","IPY_MODEL_e3354449c8c04d32b07483dd57d20b17"]}},"4357c0a10c5f466f8f70e1aa1a71daab":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"010d6762488f4f539dea79135c6c4d8c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_0bc24a15a6434ae99db37d91d6bdd1f8","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":625,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":625,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_8ca9bb26acbd4914b7bca843a7c56467"}},"e3354449c8c04d32b07483dd57d20b17":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_45f1abf51ba94fc4970e878cf57c882c","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 625/625 [00:00&lt;00:00, 2.65kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_e5bdacf6bea1439d8ef080175e5fb708"}},"0bc24a15a6434ae99db37d91d6bdd1f8":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"8ca9bb26acbd4914b7bca843a7c56467":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"45f1abf51ba94fc4970e878cf57c882c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"e5bdacf6bea1439d8ef080175e5fb708":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"076ceb2552044c3686c2adb50f421a54":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_cce8b23769fe463a9205b4c70d65f4b0","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_9f15b4e2a5734499889242d04f33f0ed","IPY_MODEL_01645e009d8e48118239cb9cec8635b2"]}},"cce8b23769fe463a9205b4c70d65f4b0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"9f15b4e2a5734499889242d04f33f0ed":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_0344e2c0c9644f71aed932360219f5d5","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":714314041,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":714314041,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_37f6f6a233704ea381f1991f1f756e8e"}},"01645e009d8e48118239cb9cec8635b2":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_c14185eedd2a46da8914592d21b4b724","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 714M/714M [00:40&lt;00:00, 17.6MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_99a364e5c53949269719a012ead19617"}},"0344e2c0c9644f71aed932360219f5d5":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"37f6f6a233704ea381f1991f1f756e8e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"c14185eedd2a46da8914592d21b4b724":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"99a364e5c53949269719a012ead19617":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"markdown","metadata":{"id":"W3vj3dcZc7mg"},"source":["# **Using a BERT Model to Predict Fake News**"]},{"cell_type":"code","metadata":{"id":"xd54-OCFdLcW"},"source":["# from google.colab import files\n","# uploaded = files.upload()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"aG7-Bozdof8_","executionInfo":{"status":"ok","timestamp":1603208393642,"user_tz":-540,"elapsed":14347,"user":{"displayName":"도리","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GigxDhsmqwbOX_7DzSWfaZBxGNeTsT52f8kX_3Y=s64","userId":"14668422416762760759"}},"outputId":"d949ae93-328f-4353-8c26-5c49b15d7348","colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["from google.colab import drive\n","drive.mount('/content/gdrive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Mounted at /content/gdrive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"7AmouJYJonaJ","executionInfo":{"status":"ok","timestamp":1603208396671,"user_tz":-540,"elapsed":872,"user":{"displayName":"도리","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GigxDhsmqwbOX_7DzSWfaZBxGNeTsT52f8kX_3Y=s64","userId":"14668422416762760759"}},"outputId":"49a915e6-43f8-45b2-ef95-359689da19c0","colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["%cd /content/gdrive/My Drive"],"execution_count":2,"outputs":[{"output_type":"stream","text":["/content/gdrive/My Drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"41J6PcG2R1fO","executionInfo":{"status":"ok","timestamp":1603208402762,"user_tz":-540,"elapsed":5147,"user":{"displayName":"도리","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GigxDhsmqwbOX_7DzSWfaZBxGNeTsT52f8kX_3Y=s64","userId":"14668422416762760759"}}},"source":["import pandas as pd\n","import numpy as np\n","import torch\n","import torch.nn as nn\n","from sklearn.model_selection import train_test_split\n","import torch.utils.data as data_utils\n","import torch.optim as optim\n","import gc #garbage collector for gpu memory \n","from tqdm import tqdm"],"execution_count":3,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"miCTWgjqTmOu"},"source":["#### The BERT package (transformers) has to be installed and run"]},{"cell_type":"code","metadata":{"id":"dkdmK8PvdtV5","executionInfo":{"status":"ok","timestamp":1603208410209,"user_tz":-540,"elapsed":10287,"user":{"displayName":"도리","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GigxDhsmqwbOX_7DzSWfaZBxGNeTsT52f8kX_3Y=s64","userId":"14668422416762760759"}}},"source":["%%capture\n","!pip install transformers"],"execution_count":4,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"N1xJfKjrpdDa"},"source":["#### Import the library specific to running BERT models on PyTorch. The transformers package using the existing PyTorch infrastructure to recreate the BERT model architecture."]},{"cell_type":"code","metadata":{"id":"vAnUF7Q1TK9t","executionInfo":{"status":"ok","timestamp":1603208423589,"user_tz":-540,"elapsed":677,"user":{"displayName":"도리","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GigxDhsmqwbOX_7DzSWfaZBxGNeTsT52f8kX_3Y=s64","userId":"14668422416762760759"}}},"source":["%%capture\n","from transformers import BertForSequenceClassification, BertTokenizer\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"],"execution_count":6,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_IxyHPxvpqID"},"source":["#### Read in the news data through the csv file. The following columns are not relevant for this endeavor:\n","\n","*   ID - this is meaningless and could cause overfitting\n","*   Title - for this experiment we'll choose to omit it\n","\n","\n"]},{"cell_type":"code","metadata":{"id":"7UtncyxgTL0C","executionInfo":{"status":"ok","timestamp":1603210994651,"user_tz":-540,"elapsed":704,"user":{"displayName":"도리","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GigxDhsmqwbOX_7DzSWfaZBxGNeTsT52f8kX_3Y=s64","userId":"14668422416762760759"}}},"source":["import pandas as pd\n","news_data = pd.read_csv(\"./Data/SNU_News.csv\",header=0)\n","\n","news_data.columns = ['text', 'label']\n","\n","news_data['text'] = news_data['text'].str.replace('\\n', '')\n","news_data['text'] = news_data['text'].str.strip()"],"execution_count":91,"outputs":[]},{"cell_type":"code","metadata":{"id":"oQ-pHke5rzxo","executionInfo":{"status":"ok","timestamp":1603211005900,"user_tz":-540,"elapsed":705,"user":{"displayName":"도리","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GigxDhsmqwbOX_7DzSWfaZBxGNeTsT52f8kX_3Y=s64","userId":"14668422416762760759"}},"outputId":"241bcfaa-ddb8-4a07-bf94-260e51a3aa9a","colab":{"base_uri":"https://localhost:8080/","height":359}},"source":["news_data.head(10)"],"execution_count":93,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>text</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>21대 총선이 끝난 지 약 5개월이 지났지만 일각의 부정선거 의혹제기로 정치권이 여...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>지난달 말 서울중앙지법이 ‘프로듀스101’(이하 프듀) 순위조작‘ 사건에 대한 1심...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>\"미국 백악관 사이트에 올린 '4·15총선 조작 의혹' 청원에 동참해 달라 그러면,...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>투표가 조작됐다는 주장은 선거 때마다 등장했다. 이번 총선에서도 한 유튜버가 사전투...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4.15 총선 인천 연수을에서 낙선한 민경욱 미래통합당 의원을 비롯해 보수성향 유튜...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>4·15 국회의원 선거(총선)의 사전투표가 10일부터 11일까지 이틀간 실시될 예정...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>4·15 총선(제21대 국회의원 선거)은 '코로나 사태' 와중임에도 별 탈 없이 끝...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>김대호 전 미래통합당 관악갑 후보는 ‘나이가 들면 모두 장애인이 된다.’는 발언으로...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>4월 10일 제21대 국회의원 선거(4월 15일) 사전투표 개시와 함께 48.1cm...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>비례대표 후보만을 낸 이른바 비례 정당들의 선거운동의 열기가 뜨겁다. 비례 정당들은...</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                                text  label\n","0  21대 총선이 끝난 지 약 5개월이 지났지만 일각의 부정선거 의혹제기로 정치권이 여...      1\n","1  지난달 말 서울중앙지법이 ‘프로듀스101’(이하 프듀) 순위조작‘ 사건에 대한 1심...      1\n","2  \"미국 백악관 사이트에 올린 '4·15총선 조작 의혹' 청원에 동참해 달라 그러면,...      1\n","3  투표가 조작됐다는 주장은 선거 때마다 등장했다. 이번 총선에서도 한 유튜버가 사전투...      1\n","4  4.15 총선 인천 연수을에서 낙선한 민경욱 미래통합당 의원을 비롯해 보수성향 유튜...      1\n","5  4·15 국회의원 선거(총선)의 사전투표가 10일부터 11일까지 이틀간 실시될 예정...      1\n","6  4·15 총선(제21대 국회의원 선거)은 '코로나 사태' 와중임에도 별 탈 없이 끝...      1\n","7  김대호 전 미래통합당 관악갑 후보는 ‘나이가 들면 모두 장애인이 된다.’는 발언으로...      1\n","8  4월 10일 제21대 국회의원 선거(4월 15일) 사전투표 개시와 함께 48.1cm...      1\n","9  비례대표 후보만을 낸 이른바 비례 정당들의 선거운동의 열기가 뜨겁다. 비례 정당들은...      1"]},"metadata":{"tags":[]},"execution_count":93}]},{"cell_type":"markdown","metadata":{"id":"xHvsxeI9Lrm6"},"source":["#### This is a preview of the data once the irrelevant columns have been removed. "]},{"cell_type":"markdown","metadata":{"id":"mD0JNbcnqHar"},"source":["#### The transformers package comes with a tokenizer for each model. We'll use the BERT tokenizer here and a BERT base model where the text isn't modified for case."]},{"cell_type":"code","metadata":{"id":"f7nUdh2bTUTv","executionInfo":{"status":"ok","timestamp":1603211024023,"user_tz":-540,"elapsed":1072,"user":{"displayName":"도리","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GigxDhsmqwbOX_7DzSWfaZBxGNeTsT52f8kX_3Y=s64","userId":"14668422416762760759"}},"outputId":"d5aea946-7c14-4aa4-850e-726453df7768","colab":{"base_uri":"https://localhost:8080/","height":67,"referenced_widgets":["259f2aba28b74cf2af2bcf21268dbf04","f863e499927d4e0f88e79fdd47fa40e7","b2379f4ecc504838b417948ea68a3854","20e2e2e370354c779fb91b024c954c8a","701083f864de40839bb8e15ce7cf0fbc","055acf729d304c34b7692ef4a8093ba0","c872cc6a9a444cc89734e6c13d74d00d","79e02ffe4ce94bd8b9f4c943099578be"]}},"source":["tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased', do_lower_case=False)"],"execution_count":94,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"259f2aba28b74cf2af2bcf21268dbf04","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=995526.0, style=ProgressStyle(descripti…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"6UUt_BlpTwKv"},"source":["#### Tokenizing the data so that each sentence is split into words and symbols. Also '[CLS]' and '[SEP]' to the beginning and end of every article."]},{"cell_type":"code","metadata":{"id":"LTygTqtPQHb0","executionInfo":{"status":"ok","timestamp":1603211024024,"user_tz":-540,"elapsed":1058,"user":{"displayName":"도리","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GigxDhsmqwbOX_7DzSWfaZBxGNeTsT52f8kX_3Y=s64","userId":"14668422416762760759"}},"outputId":"6b46f702-a173-40a3-90ef-bf20ea2ad37b","colab":{"base_uri":"https://localhost:8080/","height":217}},"source":["sentences = news_data['text']\n","sentences = [\"[CLS] \" + str(sentence) + \" [SEP]\" for sentence in sentences]\n","sentences[:10]"],"execution_count":95,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['[CLS] 21대 총선이 끝난 지 약 5개월이 지났지만 일각의 부정선거 의혹제기로 정치권이 여전히 진통을 겪고 있다.중앙선거관리위원회의 정면 반박에도 일부 전직 의원과 온라인을 중심으로 각종 의혹이 줄줄이 제기된 가운데, 지난 9일 한 온라인 커뮤니티에는 \"중앙선관위가 선거 조작의 증거인 통합선거인명부를 숨기고 있다\"는 주장이 올라왔다. [SEP]',\n"," '[CLS] 지난달 말 서울중앙지법이 ‘프로듀스101’(이하 프듀) 순위조작‘ 사건에 대한 1심 판결에서 안준영 PD에게 징역 2년과 추징금 3천700만원, 김용범 CP에게 징역 1년 8개월의 실형을 선고했다. 이 조작사건의 불똥이 4.15 총선으로 옮겨붙었다. 인터넷 커뮤니티 및 보수 유튜버 등은, ’프듀‘의 투표결과를 조작한 혐의로 실형을 선고받은 PD와 CP가 “중앙선거관리위원회의 온라인 투표시스템(K-Voting)을 이용했다”, 그래서 “4.15 총선 역시 그렇게 보안에 취약한 시스템을 이용한 조작 선거”라고 주장하고 있다. [SEP]',\n"," '[CLS] \"미국 백악관 사이트에 올린 \\'4·15총선 조작 의혹\\' 청원에 동참해 달라 그러면, 국제선관위가 나서서 지난 총선을 검증 할 수 있다\"\\xa0일부 유튜버가 주도한 부정선거 음모론의 현재 상황입니다. 백악관 청원하면 국제선관위가 한국을 조사할 수 있는지 팩트체크 해봤습니다. [SEP]',\n"," '[CLS] 투표가 조작됐다는 주장은 선거 때마다 등장했다. 이번 총선에서도 한 유튜버가 사전투표 조작 의혹을 제기했다. 서울·경기·인천에서 더불어민주당과 미래통합당의 사전투표 득표 비율이 63 대 36으로 동일하다는 게 그 근거다. 이 주장은 온라인 커뮤니티에서 빠르게 확산하고 있다. [SEP]',\n"," \"[CLS] 4.15 총선 인천 연수을에서 낙선한 민경욱 미래통합당 의원을 비롯해 보수성향 유튜버들이 '사전투표 조작 의혹'에 다시 불을 지피고 있다. 민경욱 의원은 지난 4월 27일 자신의 페이스북에 '사전투표용지 상 QR코드에 유권자의 개인정보가 담겨있고, 이 정보를 담은 서버는 4월 30일까지 복구 불가능하도록 지워진다'는 내용의 주장을 폈다. 민 의원의 주장대로 사전투표용지에 인쇄돼 있던 QR코드에는 개인정보가 담겨있는 걸까. 또 '사전선거관리시스템'의 정체는 무엇일까. 중앙선거관리위원회에 직접 질의해 팩트체크했다. [SEP]\",\n"," '[CLS] 4·15 국회의원 선거(총선)의 사전투표가 10일부터 11일까지 이틀간 실시될 예정인 가운데 신종 코로나바이러스 감염증(코로나19) 예방을 위해 유권자들이 지켜야 할 수칙에 대한 관심이 크다. 가장 이목이 집중되는 사항은 마스크 착용에 대한 것이다. 중앙선거관리위원회가 코로나19 예방을 위해 투표소에 갈 때는 반드시 마스크를 착용하도록 권고하면서, 일부 유권자들은 마스크를 착용하지 않으면 아예 투표를 할 수 없는 것으로 생각하는 듯 하다. 인터넷 커뮤니티 등에서는 \"마스크가 없어 안 쓰고 투표소에 가면 투표 못 한다\"라거나 \"마스크 없다고 투표권을 박탈했다가 헌법재판소에 소송을 내면 선거가 무효화될 것\"이라는 등의 글이 올라왔다. [SEP]',\n"," '[CLS] 4·15 총선(제21대 국회의원 선거)은 \\'코로나 사태\\' 와중임에도 별 탈 없이 끝났지만 여느 선거와 마찬가지로 일부의 \\'의혹 제기\\'는 있었다. 보수성향 유튜브 채널인 \\'신의한수\\'는 선거 당일인 15일 파쇄 종이 더미가 찍힌 사진들과 \\'여주 선관위 건물로 보인다\\'는 한 건물 외경 사진을 제시하며 투표용지 파쇄 의혹이 거론되고 있다고 방송했다. 해당 영상에 따르면 이 매체의 한 기자는 \"경기 여주시 부근에서 선관위 건물 밖에서 파쇄된 투표용지가 발견됐다는 의혹도 제기되고 있다\"며 사전 투표때 기표한 투표용지를 파쇄해서 폐기한 것이 아니냐는 주장이 있다고 소개했다. 그는 \\'선거 전 모의 테스트후 파쇄한 용지들이 폐기된 것\\'이라는 중앙선거관리위원회와 지역 선관위의 설명을 소개하긴 했지만 \"왜 파쇄가 됐는지 의혹이 드는 상황\", \"이것을 통해서 무엇을 얻고자 했는지 굉장히 당혹스럽고 굉장히 충격적인 사실\" 등의 말을 덧붙이며 의혹이 가시지 않았다는 뉘앙스를 전했다. \\xa0그는 또 \"사실 여주뿐만 아니라 비슷한 의혹은 (서울) 동작에서도 제기가 되고 있어서 투표 결과에 대해 믿을 만한 것인지 의혹이 드는 부분\"이라고도 말했다. 이 건과 관련, 일부 인터넷 커뮤니티 등에서는 \\'선거 부정 의혹\\'을 제기하는 글까지 올라왔다. \"표 바꿔치기\",\"밤에 몰래 사전투표 (용지를) 파쇄하고 민주당표로 갈아치운 거 아니냐?\"는 등의 주장이었다. [SEP]',\n"," '[CLS] 김대호 전 미래통합당 관악갑 후보는 ‘나이가 들면 모두 장애인이 된다.’는 발언으로 논란이 돼 당에서 제명됐습니다. 김 전 후보는 페이스북에 글을 올려 논란이 된 발언을 기사화한 언론 보도를 문제 삼았습니다. 김 전 후보의 말대로 후보자 토론회 방송 전 후보자 한명의 발언만 먼저 기사화한 경우가 위법 소지가 있는지 확인해봤습니다. [SEP]',\n"," \"[CLS] 4월 10일 제21대 국회의원 선거(4월 15일) 사전투표 개시와 함께 48.1cm 짜리 비례대표용 투표용지도 국내 유권자들에게 정식으로 선을 보였다.35개 정당의 이름이 새겨진 '역대급' 투표용지인 만큼 여러 면에서 관심을 끌고 있는데 '접는 방법'에 대한 궁금증도 적지 않다. 인터넷에는 '종이접는 게 더 신경 쓰이긴 처음이네요', '사전투표 하려고 하는데 투표후 투표용지 접을 때 세로? 가로?'와 같은 글에서부터 '세로로 접어야되는데 가로로 접어서 무효표 됨', '재외선거 투표때 투표용지 가로로 접음. 그렇게 안접으면 봉투에 안 들어감. 잘 가 내 무효표 ㅜㅜ'와 같은 '팩트체크'가 필요한 글까지 다양하게 올라와 있다. 뿐만 아니라 용지가 기표된 부분에 닿지 않게끔 접는 방법을 담은 사진도 올라와 있고 '가로로 접으면 무효표가 될 수 있으니 세로로 접으라'는 '비공인' 안내글도 있다. [SEP]\",\n"," '[CLS] 비례대표 후보만을 낸 이른바 비례 정당들의 선거운동의 열기가 뜨겁다. 비례 정당들은 지역구 정당과의 연관성을 부각하기 위해 각종 꼼수도 활용하고 있다. 주로 비례 정당 후보가 손가락으로 자신이 속한 정당의 기호와 지역구 정당 후보의 기호를 함께 표시하면서 ‘자매 정당’인 점을 강조하고 있다. 지역구 정당과 비례 정당 후보들이 서로 도와서 유세를 할 때 종종 목격되는 모습인데, 더불어민주당과 더불어시민당은 각 당의 기호인 숫자 1과 5를, 미래통합당과 미래한국당은 2와 4를 함께 홍보하는 식이다. 선거법에 저촉되는 것은 아닌지 따져봤다. [SEP]']"]},"metadata":{"tags":[]},"execution_count":95}]},{"cell_type":"code","metadata":{"id":"GCro7M4oXX-l","executionInfo":{"status":"ok","timestamp":1603211024025,"user_tz":-540,"elapsed":1041,"user":{"displayName":"도리","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GigxDhsmqwbOX_7DzSWfaZBxGNeTsT52f8kX_3Y=s64","userId":"14668422416762760759"}},"outputId":"e179f7d6-f1bf-446a-ed07-f40ab0d136ba","colab":{"base_uri":"https://localhost:8080/","height":55}},"source":["tokenized_df = [tokenizer.tokenize(sent)[:510] for sent in sentences]\n","\n","print (tokenized_df[0])"],"execution_count":96,"outputs":[{"output_type":"stream","text":["['[CLS]', '21', '##대', '총', '##선', '##이', '끝', '##난', '지', '약', '5', '##개', '##월', '##이', '지', '##났', '##지만', '일', '##각', '##의', '부', '##정', '##선', '##거', '의', '##혹', '##제', '##기로', '정', '##치', '##권', '##이', '여', '##전', '##히', '진', '##통', '##을', '겪', '##고', '있다', '.', '중', '##앙', '##선', '##거', '##관', '##리', '##위원회', '##의', '정', '##면', '반', '##박', '##에도', '일부', '전', '##직', '의', '##원', '##과', '온', '##라', '##인을', '중심으로', '각', '##종', '의', '##혹', '##이', '줄', '##줄', '##이', '제', '##기', '##된', '가운데', ',', '지', '##난', '9일', '한', '온', '##라', '##인', '커', '##뮤', '##니', '##티', '##에는', '\"', '중', '##앙', '##선', '##관', '##위', '##가', '선', '##거', '조', '##작', '##의', '증', '##거', '##인', '통', '##합', '##선', '##거', '##인', '##명', '##부를', '숨', '##기', '##고', '있다', '\"', '는', '주', '##장이', '올', '##라', '##왔다', '.', '[SEP]']\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"fTU3g0utTWih","executionInfo":{"status":"ok","timestamp":1603211024025,"user_tz":-540,"elapsed":1038,"user":{"displayName":"도리","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GigxDhsmqwbOX_7DzSWfaZBxGNeTsT52f8kX_3Y=s64","userId":"14668422416762760759"}}},"source":["# tokenized_df = list(map(lambda t: ['[CLS]'] + tokenizer.tokenize(t)[:510] + ['[SEP]'], news_data['text']))"],"execution_count":97,"outputs":[]},{"cell_type":"code","metadata":{"id":"c_miXPp_PRI-","executionInfo":{"status":"ok","timestamp":1603211024026,"user_tz":-540,"elapsed":1037,"user":{"displayName":"도리","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GigxDhsmqwbOX_7DzSWfaZBxGNeTsT52f8kX_3Y=s64","userId":"14668422416762760759"}}},"source":["# tokenized_df = [['[CLS]'] + tokenizer.tokenize(sent)[:510] + ['[SEP]'] for sent in news_data['text']]"],"execution_count":98,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"JUeF9eIgT_71"},"source":["#### The max input length for a BERT algorithm is 512, so we'll have to pad each article to this length or cut it short."]},{"cell_type":"code","metadata":{"id":"bUH2aaTuT9mE","executionInfo":{"status":"ok","timestamp":1603211024321,"user_tz":-540,"elapsed":1325,"user":{"displayName":"도리","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GigxDhsmqwbOX_7DzSWfaZBxGNeTsT52f8kX_3Y=s64","userId":"14668422416762760759"}}},"source":["totalpadlength = 512"],"execution_count":99,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"qC2N768vUOd9"},"source":["#### We need to get the index for each token so that we can map them to be put in a matrix embedding."]},{"cell_type":"code","metadata":{"id":"u_J8Nx-3UIMN","executionInfo":{"status":"ok","timestamp":1603211024321,"user_tz":-540,"elapsed":1322,"user":{"displayName":"도리","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GigxDhsmqwbOX_7DzSWfaZBxGNeTsT52f8kX_3Y=s64","userId":"14668422416762760759"}}},"source":["indexed_tokens = list(map(tokenizer.convert_tokens_to_ids, tokenized_df))"],"execution_count":100,"outputs":[]},{"cell_type":"code","metadata":{"id":"dBO7O7InULoP","executionInfo":{"status":"ok","timestamp":1603211024322,"user_tz":-540,"elapsed":1317,"user":{"displayName":"도리","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GigxDhsmqwbOX_7DzSWfaZBxGNeTsT52f8kX_3Y=s64","userId":"14668422416762760759"}}},"source":["index_padded = np.array([xi+[0]*(totalpadlength-len(xi)) for xi in indexed_tokens])"],"execution_count":101,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"HUfJOQbQU7Wp"},"source":["#### Setting up an array with the binary target variable values\n","* 0 = FAKE\n","* 1 = REAL"]},{"cell_type":"code","metadata":{"id":"6fQrmWLdUeJf","executionInfo":{"status":"ok","timestamp":1603211024322,"user_tz":-540,"elapsed":1314,"user":{"displayName":"도리","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GigxDhsmqwbOX_7DzSWfaZBxGNeTsT52f8kX_3Y=s64","userId":"14668422416762760759"}}},"source":["target_variable = news_data['label'].values"],"execution_count":102,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"8GNfTz1DVBID"},"source":["#### Creating dictionaries that map the tokens to the index and the index to the token."]},{"cell_type":"code","metadata":{"id":"GShqmScmU5Ma","executionInfo":{"status":"ok","timestamp":1603211024322,"user_tz":-540,"elapsed":1311,"user":{"displayName":"도리","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GigxDhsmqwbOX_7DzSWfaZBxGNeTsT52f8kX_3Y=s64","userId":"14668422416762760759"}}},"source":["all_words = []\n","for l in tokenized_df:\n","  all_words.extend(l)\n","all_indices = []\n","for i in indexed_tokens:\n","  all_indices.extend(i)\n","\n","word_to_ix = dict(zip(all_words, all_indices))\n","ix_to_word = dict(zip(all_indices, all_words))"],"execution_count":103,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"biX1BjKtVGb_"},"source":["#### The BERT algorithm relies on masking to help it learn and to prevent overfitting, so we'll add this to the model."]},{"cell_type":"code","metadata":{"id":"mWzKFbd2VEGh","executionInfo":{"status":"ok","timestamp":1603211024323,"user_tz":-540,"elapsed":1309,"user":{"displayName":"도리","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GigxDhsmqwbOX_7DzSWfaZBxGNeTsT52f8kX_3Y=s64","userId":"14668422416762760759"}}},"source":["mask_variable = [[float(i>0) for i in ii] for ii in index_padded]"],"execution_count":104,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"a8NxoJyMVPnz"},"source":["#### This loads the data into train and test dataloaders, which for PyTorch is necessary to iterate through the algorithm."]},{"cell_type":"code","metadata":{"id":"0EGCS8atVN5w","executionInfo":{"status":"ok","timestamp":1603211024323,"user_tz":-540,"elapsed":1307,"user":{"displayName":"도리","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GigxDhsmqwbOX_7DzSWfaZBxGNeTsT52f8kX_3Y=s64","userId":"14668422416762760759"}}},"source":["BATCH_SIZE = 14\n","def format_tensors(text_data, mask, labels, batch_size):\n","    X = torch.from_numpy(text_data)\n","    X = X.long()\n","    mask = torch.tensor(mask)\n","    y = torch.from_numpy(labels)\n","    y = y.long()\n","    tensordata = data_utils.TensorDataset(X, mask, y)\n","    loader = data_utils.DataLoader(tensordata, batch_size=batch_size, shuffle=False)\n","    return loader\n","\n","X_train, X_test, y_train, y_test = train_test_split(index_padded, target_variable, \n","                                                    test_size=0.1, random_state=42)\n","\n","train_masks, test_masks, _, _ = train_test_split(mask_variable, index_padded, \n","                                                       test_size=0.1, random_state=42)\n","\n","trainloader = format_tensors(X_train, train_masks, y_train,BATCH_SIZE)\n","testloader = format_tensors(X_test, test_masks, y_test, BATCH_SIZE)"],"execution_count":105,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-g05NLG2VmMe"},"source":["#### This is a sample batch from the trainloader. The first tensor contains the embeddings for the articles, the second tensor contains the masking information, and the third tensor contains the target variables for each article."]},{"cell_type":"code","metadata":{"id":"zfSbQJciVaJY","executionInfo":{"status":"ok","timestamp":1603211024599,"user_tz":-540,"elapsed":1575,"user":{"displayName":"도리","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GigxDhsmqwbOX_7DzSWfaZBxGNeTsT52f8kX_3Y=s64","userId":"14668422416762760759"}},"outputId":"be10ba31-8ad2-4c0f-bd58-e843ce38fa62","colab":{"base_uri":"https://localhost:8080/","height":287}},"source":["next(iter(trainloader))"],"execution_count":106,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[tensor([[  101,  9487, 22200,  ...,     0,     0,     0],\n","         [  101,  9319, 16323,  ...,     0,     0,     0],\n","         [  101,  9565, 21928,  ...,     0,     0,     0],\n","         ...,\n","         [  101,  9487, 22200,  ...,     0,     0,     0],\n","         [  101,   107, 42608,  ...,     0,     0,     0],\n","         [  101,   107,  9812,  ...,     0,     0,     0]]),\n"," tensor([[1., 1., 1.,  ..., 0., 0., 0.],\n","         [1., 1., 1.,  ..., 0., 0., 0.],\n","         [1., 1., 1.,  ..., 0., 0., 0.],\n","         ...,\n","         [1., 1., 1.,  ..., 0., 0., 0.],\n","         [1., 1., 1.,  ..., 0., 0., 0.],\n","         [1., 1., 1.,  ..., 0., 0., 0.]]),\n"," tensor([1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1])]"]},"metadata":{"tags":[]},"execution_count":106}]},{"cell_type":"markdown","metadata":{"id":"eJhkInO_V03B"},"source":["\n","### Now it's time to create the BERT Model!"]},{"cell_type":"markdown","metadata":{"id":"P0zItZ3SV8Uy"},"source":["#### The BERT model architecture is shown below. This is a BERT base-cased model, which means it has 12 BERT transformer layers, 768 hidden layers, 12 heads, 110M parameters, and is pre-trained on cased English text.\n"]},{"cell_type":"code","metadata":{"id":"zMzcRtjmVghX","executionInfo":{"status":"ok","timestamp":1603211065351,"user_tz":-540,"elapsed":42319,"user":{"displayName":"도리","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GigxDhsmqwbOX_7DzSWfaZBxGNeTsT52f8kX_3Y=s64","userId":"14668422416762760759"}},"outputId":"4752760d-c833-4a01-946b-c0f39f4a537c","colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["e4207e73745b442faa006566de58ce3b","4357c0a10c5f466f8f70e1aa1a71daab","010d6762488f4f539dea79135c6c4d8c","e3354449c8c04d32b07483dd57d20b17","0bc24a15a6434ae99db37d91d6bdd1f8","8ca9bb26acbd4914b7bca843a7c56467","45f1abf51ba94fc4970e878cf57c882c","e5bdacf6bea1439d8ef080175e5fb708","076ceb2552044c3686c2adb50f421a54","cce8b23769fe463a9205b4c70d65f4b0","9f15b4e2a5734499889242d04f33f0ed","01645e009d8e48118239cb9cec8635b2","0344e2c0c9644f71aed932360219f5d5","37f6f6a233704ea381f1991f1f756e8e","c14185eedd2a46da8914592d21b4b724","99a364e5c53949269719a012ead19617"]}},"source":["model = BertForSequenceClassification.from_pretrained('bert-base-multilingual-cased', output_hidden_states = True)\n","model"],"execution_count":107,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e4207e73745b442faa006566de58ce3b","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=625.0, style=ProgressStyle(description_…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"076ceb2552044c3686c2adb50f421a54","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=714314041.0, style=ProgressStyle(descri…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["BertForSequenceClassification(\n","  (bert): BertModel(\n","    (embeddings): BertEmbeddings(\n","      (word_embeddings): Embedding(119547, 768, padding_idx=0)\n","      (position_embeddings): Embedding(512, 768)\n","      (token_type_embeddings): Embedding(2, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): BertEncoder(\n","      (layer): ModuleList(\n","        (0): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (1): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (2): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (3): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (4): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (5): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (6): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (7): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (8): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (9): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (10): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (11): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (pooler): BertPooler(\n","      (dense): Linear(in_features=768, out_features=768, bias=True)\n","      (activation): Tanh()\n","    )\n","  )\n","  (dropout): Dropout(p=0.1, inplace=False)\n","  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",")"]},"metadata":{"tags":[]},"execution_count":107}]},{"cell_type":"markdown","metadata":{"id":"RTfAMHLqWCbm"},"source":["#### Creating a function to compute the accuracy after each epoch"]},{"cell_type":"code","metadata":{"id":"o8I-otafV5rn","executionInfo":{"status":"ok","timestamp":1603211065352,"user_tz":-540,"elapsed":42316,"user":{"displayName":"도리","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GigxDhsmqwbOX_7DzSWfaZBxGNeTsT52f8kX_3Y=s64","userId":"14668422416762760759"}}},"source":["def compute_accuracy(model, dataloader, device):\n","    tqdm()\n","    model.eval()\n","    correct_preds, num_samples = 0,0\n","    with torch.no_grad():\n","        for i, batch in enumerate(tqdm(dataloader)):\n","            token_ids, masks, labels = tuple(t.to(device) for t in batch)\n","            _, yhat, hidden = model(input_ids=token_ids, attention_mask=masks, labels=labels)\n","            prediction = (torch.sigmoid(yhat[:,1]) > 0.5).long()\n","            num_samples += labels.size(0)\n","            correct_preds += (prediction==labels.long()).sum()\n","            del token_ids, masks, labels #memory\n","        torch.cuda.empty_cache() #memory\n","        gc.collect() # memory\n","        return correct_preds.float()/num_samples*100"],"execution_count":108,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Z5SbPkIiWSup"},"source":["#### Now we iterate through the dataset, updating the model weights at each instance. Since BERT is pre-trained, we keep the learning rate low and only perform a few epochs. This prevents it from overfitting."]},{"cell_type":"code","metadata":{"id":"C1Bb31svWIQe","executionInfo":{"status":"ok","timestamp":1603211673127,"user_tz":-540,"elapsed":650083,"user":{"displayName":"도리","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GigxDhsmqwbOX_7DzSWfaZBxGNeTsT52f8kX_3Y=s64","userId":"14668422416762760759"}},"outputId":"b4774534-3b30-4328-d3ab-dc2b0445046e","colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","torch.cuda.empty_cache() #memory\n","gc.collect() #memory\n","NUM_EPOCHS = 30\n","loss_function = nn.BCEWithLogitsLoss()\n","losses = []\n","model.to(device)\n","optimizer = optim.Adam(model.parameters(), lr=3e-6)\n","for epoch in range(NUM_EPOCHS):\n","    model.train()\n","    running_loss = 0.0\n","    iteration = 0\n","    for i, batch in enumerate(trainloader):\n","        iteration += 1\n","        token_ids, masks, labels = tuple(t.to(device) for t in batch)\n","        optimizer.zero_grad()\n","        loss, yhat, hidden = model(input_ids=token_ids, attention_mask=masks, labels=labels)\n","        loss.backward()\n","        optimizer.step()\n","        running_loss += float(loss.item())\n","        del token_ids, masks, labels #memory\n","    \n","        if not i%25:\n","            print(f'Epoch: {epoch+1:03d}/{NUM_EPOCHS:03d} | '\n","                  f'Batch {i+1:03d}/{len(trainloader):03d} | '\n","                  f'Average Loss in last {iteration} iteration(s): {(running_loss/iteration):.4f}')\n","            running_loss = 0.0\n","            iteration = 0\n","        torch.cuda.empty_cache() #memory\n","        gc.collect() #memory\n","        losses.append(float(loss.item()))\n","    with torch.set_grad_enabled(False):\n","        print(f'\\nTraining Accuracy: '\n","              f'{compute_accuracy(model, trainloader, device):.2f}%')\n","        \n"],"execution_count":109,"outputs":[{"output_type":"stream","text":["Epoch: 001/030 | Batch 001/014 | Average Loss in last 1 iteration(s): 0.6852\n"],"name":"stdout"},{"output_type":"stream","text":["0it [00:00, ?it/s]\n","100%|██████████| 14/14 [00:03<00:00,  4.46it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["\n","Training Accuracy: 55.03%\n","Epoch: 002/030 | Batch 001/014 | Average Loss in last 1 iteration(s): 0.6732\n"],"name":"stdout"},{"output_type":"stream","text":["0it [00:00, ?it/s]\n","100%|██████████| 14/14 [00:03<00:00,  4.45it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["\n","Training Accuracy: 59.26%\n","Epoch: 003/030 | Batch 001/014 | Average Loss in last 1 iteration(s): 0.6606\n"],"name":"stdout"},{"output_type":"stream","text":["0it [00:00, ?it/s]\n","100%|██████████| 14/14 [00:03<00:00,  4.46it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["\n","Training Accuracy: 62.43%\n","Epoch: 004/030 | Batch 001/014 | Average Loss in last 1 iteration(s): 0.6550\n"],"name":"stdout"},{"output_type":"stream","text":["0it [00:00, ?it/s]\n","100%|██████████| 14/14 [00:03<00:00,  4.45it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["\n","Training Accuracy: 77.25%\n","Epoch: 005/030 | Batch 001/014 | Average Loss in last 1 iteration(s): 0.6180\n"],"name":"stdout"},{"output_type":"stream","text":["0it [00:00, ?it/s]\n","100%|██████████| 14/14 [00:03<00:00,  4.46it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["\n","Training Accuracy: 80.42%\n","Epoch: 006/030 | Batch 001/014 | Average Loss in last 1 iteration(s): 0.5339\n"],"name":"stdout"},{"output_type":"stream","text":["0it [00:00, ?it/s]\n","100%|██████████| 14/14 [00:03<00:00,  4.45it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["\n","Training Accuracy: 86.24%\n","Epoch: 007/030 | Batch 001/014 | Average Loss in last 1 iteration(s): 0.4483\n"],"name":"stdout"},{"output_type":"stream","text":["0it [00:00, ?it/s]\n","100%|██████████| 14/14 [00:03<00:00,  4.46it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["\n","Training Accuracy: 88.89%\n","Epoch: 008/030 | Batch 001/014 | Average Loss in last 1 iteration(s): 0.3546\n"],"name":"stdout"},{"output_type":"stream","text":["0it [00:00, ?it/s]\n","100%|██████████| 14/14 [00:03<00:00,  4.46it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["\n","Training Accuracy: 88.89%\n","Epoch: 009/030 | Batch 001/014 | Average Loss in last 1 iteration(s): 0.2979\n"],"name":"stdout"},{"output_type":"stream","text":["0it [00:00, ?it/s]\n","100%|██████████| 14/14 [00:03<00:00,  4.46it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["\n","Training Accuracy: 93.65%\n","Epoch: 010/030 | Batch 001/014 | Average Loss in last 1 iteration(s): 0.1817\n"],"name":"stdout"},{"output_type":"stream","text":["0it [00:00, ?it/s]\n","100%|██████████| 14/14 [00:03<00:00,  4.45it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["\n","Training Accuracy: 96.30%\n","Epoch: 011/030 | Batch 001/014 | Average Loss in last 1 iteration(s): 0.1320\n"],"name":"stdout"},{"output_type":"stream","text":["0it [00:00, ?it/s]\n","100%|██████████| 14/14 [00:03<00:00,  4.46it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["\n","Training Accuracy: 98.41%\n","Epoch: 012/030 | Batch 001/014 | Average Loss in last 1 iteration(s): 0.1000\n"],"name":"stdout"},{"output_type":"stream","text":["0it [00:00, ?it/s]\n","100%|██████████| 14/14 [00:03<00:00,  4.46it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["\n","Training Accuracy: 97.88%\n","Epoch: 013/030 | Batch 001/014 | Average Loss in last 1 iteration(s): 0.0824\n"],"name":"stdout"},{"output_type":"stream","text":["0it [00:00, ?it/s]\n","100%|██████████| 14/14 [00:03<00:00,  4.46it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["\n","Training Accuracy: 98.41%\n","Epoch: 014/030 | Batch 001/014 | Average Loss in last 1 iteration(s): 0.0515\n"],"name":"stdout"},{"output_type":"stream","text":["0it [00:00, ?it/s]\n","100%|██████████| 14/14 [00:03<00:00,  4.46it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["\n","Training Accuracy: 98.41%\n","Epoch: 015/030 | Batch 001/014 | Average Loss in last 1 iteration(s): 0.0633\n"],"name":"stdout"},{"output_type":"stream","text":["0it [00:00, ?it/s]\n","100%|██████████| 14/14 [00:03<00:00,  4.46it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["\n","Training Accuracy: 98.41%\n","Epoch: 016/030 | Batch 001/014 | Average Loss in last 1 iteration(s): 0.0342\n"],"name":"stdout"},{"output_type":"stream","text":["0it [00:00, ?it/s]\n","100%|██████████| 14/14 [00:03<00:00,  4.46it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["\n","Training Accuracy: 98.94%\n","Epoch: 017/030 | Batch 001/014 | Average Loss in last 1 iteration(s): 0.0295\n"],"name":"stdout"},{"output_type":"stream","text":["0it [00:00, ?it/s]\n","100%|██████████| 14/14 [00:03<00:00,  4.46it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["\n","Training Accuracy: 98.94%\n","Epoch: 018/030 | Batch 001/014 | Average Loss in last 1 iteration(s): 0.0427\n"],"name":"stdout"},{"output_type":"stream","text":["0it [00:00, ?it/s]\n","100%|██████████| 14/14 [00:03<00:00,  4.46it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["\n","Training Accuracy: 98.94%\n","Epoch: 019/030 | Batch 001/014 | Average Loss in last 1 iteration(s): 0.0272\n"],"name":"stdout"},{"output_type":"stream","text":["0it [00:00, ?it/s]\n","100%|██████████| 14/14 [00:03<00:00,  4.46it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["\n","Training Accuracy: 98.94%\n","Epoch: 020/030 | Batch 001/014 | Average Loss in last 1 iteration(s): 0.0170\n"],"name":"stdout"},{"output_type":"stream","text":["0it [00:00, ?it/s]\n","100%|██████████| 14/14 [00:03<00:00,  4.46it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["\n","Training Accuracy: 98.94%\n","Epoch: 021/030 | Batch 001/014 | Average Loss in last 1 iteration(s): 0.0169\n"],"name":"stdout"},{"output_type":"stream","text":["0it [00:00, ?it/s]\n","100%|██████████| 14/14 [00:03<00:00,  4.46it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["\n","Training Accuracy: 98.94%\n","Epoch: 022/030 | Batch 001/014 | Average Loss in last 1 iteration(s): 0.0136\n"],"name":"stdout"},{"output_type":"stream","text":["0it [00:00, ?it/s]\n","100%|██████████| 14/14 [00:03<00:00,  4.46it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["\n","Training Accuracy: 98.94%\n","Epoch: 023/030 | Batch 001/014 | Average Loss in last 1 iteration(s): 0.0127\n"],"name":"stdout"},{"output_type":"stream","text":["0it [00:00, ?it/s]\n","100%|██████████| 14/14 [00:03<00:00,  4.46it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["\n","Training Accuracy: 98.41%\n","Epoch: 024/030 | Batch 001/014 | Average Loss in last 1 iteration(s): 0.0128\n"],"name":"stdout"},{"output_type":"stream","text":["0it [00:00, ?it/s]\n","100%|██████████| 14/14 [00:03<00:00,  4.45it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["\n","Training Accuracy: 98.41%\n","Epoch: 025/030 | Batch 001/014 | Average Loss in last 1 iteration(s): 0.0153\n"],"name":"stdout"},{"output_type":"stream","text":["0it [00:00, ?it/s]\n","100%|██████████| 14/14 [00:03<00:00,  4.45it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["\n","Training Accuracy: 98.41%\n","Epoch: 026/030 | Batch 001/014 | Average Loss in last 1 iteration(s): 0.0111\n"],"name":"stdout"},{"output_type":"stream","text":["0it [00:00, ?it/s]\n","100%|██████████| 14/14 [00:03<00:00,  4.46it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["\n","Training Accuracy: 98.41%\n","Epoch: 027/030 | Batch 001/014 | Average Loss in last 1 iteration(s): 0.0099\n"],"name":"stdout"},{"output_type":"stream","text":["0it [00:00, ?it/s]\n","100%|██████████| 14/14 [00:03<00:00,  4.46it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["\n","Training Accuracy: 98.41%\n","Epoch: 028/030 | Batch 001/014 | Average Loss in last 1 iteration(s): 0.0103\n"],"name":"stdout"},{"output_type":"stream","text":["0it [00:00, ?it/s]\n","100%|██████████| 14/14 [00:03<00:00,  4.46it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["\n","Training Accuracy: 98.41%\n","Epoch: 029/030 | Batch 001/014 | Average Loss in last 1 iteration(s): 0.0081\n"],"name":"stdout"},{"output_type":"stream","text":["0it [00:00, ?it/s]\n","100%|██████████| 14/14 [00:03<00:00,  4.46it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["\n","Training Accuracy: 98.41%\n","Epoch: 030/030 | Batch 001/014 | Average Loss in last 1 iteration(s): 0.0083\n"],"name":"stdout"},{"output_type":"stream","text":["0it [00:00, ?it/s]\n","100%|██████████| 14/14 [00:03<00:00,  4.46it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["\n","Training Accuracy: 98.41%\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"aXUTev8wUDpX","executionInfo":{"status":"ok","timestamp":1603212089758,"user_tz":-540,"elapsed":5263,"user":{"displayName":"도리","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GigxDhsmqwbOX_7DzSWfaZBxGNeTsT52f8kX_3Y=s64","userId":"14668422416762760759"}}},"source":["export_dir='./saved_SNU_fakenews_Data_model'\n","torch.save(model, export_dir)"],"execution_count":121,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2ixSdyDXL1ww"},"source":["#### Finally, we score the final model on the test set"]},{"cell_type":"code","metadata":{"id":"BAu6Y4pSL1Vf","executionInfo":{"status":"ok","timestamp":1603211673685,"user_tz":-540,"elapsed":650625,"user":{"displayName":"도리","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GigxDhsmqwbOX_7DzSWfaZBxGNeTsT52f8kX_3Y=s64","userId":"14668422416762760759"}},"outputId":"7c2efdcc-f26c-4e78-944b-f7cd719248a6","colab":{"base_uri":"https://localhost:8080/","height":107}},"source":["with torch.set_grad_enabled(False):\n","  print(f'\\n\\nTest Accuracy:'\n","  f'{compute_accuracy(model, testloader, device):.2f}%')"],"execution_count":111,"outputs":[{"output_type":"stream","text":["0it [00:00, ?it/s]\n","100%|██████████| 2/2 [00:00<00:00,  7.73it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["\n","\n","Test Accuracy:80.95%\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"gxF5RZzgNmJF"},"source":["#### We then do some error analysis by gathering the articles that were incorrectly predicted and analyzing the text of the articles."]},{"cell_type":"code","metadata":{"id":"u9jq78QlMpbL","executionInfo":{"status":"ok","timestamp":1603211674377,"user_tz":-540,"elapsed":651307,"user":{"displayName":"도리","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GigxDhsmqwbOX_7DzSWfaZBxGNeTsT52f8kX_3Y=s64","userId":"14668422416762760759"}},"outputId":"b8f5cd57-d747-410d-d73f-384823ff0b90","colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["test_predictions = torch.zeros((len(y_test),1))\n","test_predictions_percent = torch.zeros((len(y_test),1))\n","with torch.no_grad():\n","  for i, batch in enumerate(tqdm(testloader)):\n","    token_ids, masks, labels = tuple(t.to(device) for t in batch)\n","    _, yhat, hidden = model(input_ids=token_ids, attention_mask=masks, labels=labels)\n","    prediction = (torch.sigmoid(yhat[:,1]) > 0.5).long().view(-1,1)\n","    test_predictions[i*BATCH_SIZE:(i+1)*BATCH_SIZE] = prediction\n","    test_predictions_percent[i*BATCH_SIZE:(i+1)*BATCH_SIZE] = torch.sigmoid(yhat[:,1]).view(-1,1)"],"execution_count":112,"outputs":[{"output_type":"stream","text":["100%|██████████| 2/2 [00:00<00:00,  5.33it/s]\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"qG-KPbFqMpih","executionInfo":{"status":"ok","timestamp":1603211674379,"user_tz":-540,"elapsed":651305,"user":{"displayName":"도리","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GigxDhsmqwbOX_7DzSWfaZBxGNeTsT52f8kX_3Y=s64","userId":"14668422416762760759"}}},"source":["X_train_words, X_test_words, y_train_words, y_test_words = train_test_split(news_data['text'], target_variable, \n","                                                    test_size=0.1, random_state=42)"],"execution_count":113,"outputs":[]},{"cell_type":"code","metadata":{"id":"Phlxie3NMpnv","executionInfo":{"status":"ok","timestamp":1603211674380,"user_tz":-540,"elapsed":651303,"user":{"displayName":"도리","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GigxDhsmqwbOX_7DzSWfaZBxGNeTsT52f8kX_3Y=s64","userId":"14668422416762760759"}}},"source":["final_results = X_test_words.to_frame().reset_index(drop=True)\n","final_results['predicted'] = np.array(test_predictions.reshape(-1), dtype=int).tolist()\n","final_results['percent'] = np.array(test_predictions_percent.reshape(-1), dtype=float).tolist()\n","final_results['actual'] = y_test_words\n","wrong_results = final_results.loc[final_results['predicted']!=final_results['actual']].copy()\n"],"execution_count":114,"outputs":[]},{"cell_type":"code","metadata":{"id":"28h0Xz3VMpq4","executionInfo":{"status":"ok","timestamp":1603211674381,"user_tz":-540,"elapsed":651294,"user":{"displayName":"도리","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GigxDhsmqwbOX_7DzSWfaZBxGNeTsT52f8kX_3Y=s64","userId":"14668422416762760759"}},"outputId":"f822c2f7-1f52-462a-8093-dfeeeeb93649","colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["print('Number of incorrectly classified articles:', len(wrong_results))"],"execution_count":115,"outputs":[{"output_type":"stream","text":["Number of incorrectly classified articles: 4\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"yejVOpxzPSLc"},"source":["#### This displays the incorrectly predicted instances, along with the percent confidence the algorithm had in each instance. The threshold for classification is 50%. Instances closer to 100% are more confident it's real news and instances closer to 0% are more confident it's fake news."]},{"cell_type":"code","metadata":{"id":"D7Wzg5EINQZv","executionInfo":{"status":"ok","timestamp":1603211674382,"user_tz":-540,"elapsed":651287,"user":{"displayName":"도리","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GigxDhsmqwbOX_7DzSWfaZBxGNeTsT52f8kX_3Y=s64","userId":"14668422416762760759"}},"outputId":"526b2af5-53a7-4ad1-c0f2-4ee9988cbbd2","colab":{"base_uri":"https://localhost:8080/","height":345}},"source":["wrong_results.loc[:,'text_short'] = wrong_results.loc[:,'text'].apply(lambda x: x[:500])\n","wrong_results.loc[:,('text_short', 'percent','predicted','actual')].style.set_properties(subset=['text_short'], **{'width': '1000px', 'white-space':'pre-wrap'})"],"execution_count":116,"outputs":[{"output_type":"execute_result","data":{"text/html":["<style  type=\"text/css\" >\n","#T_22b2b024_12f2_11eb_8446_0242ac1c0002row0_col0,#T_22b2b024_12f2_11eb_8446_0242ac1c0002row1_col0,#T_22b2b024_12f2_11eb_8446_0242ac1c0002row2_col0,#T_22b2b024_12f2_11eb_8446_0242ac1c0002row3_col0{\n","            width:  1000px;\n","            white-space:  pre-wrap;\n","        }</style><table id=\"T_22b2b024_12f2_11eb_8446_0242ac1c0002\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >text_short</th>        <th class=\"col_heading level0 col1\" >percent</th>        <th class=\"col_heading level0 col2\" >predicted</th>        <th class=\"col_heading level0 col3\" >actual</th>    </tr></thead><tbody>\n","                <tr>\n","                        <th id=\"T_22b2b024_12f2_11eb_8446_0242ac1c0002level0_row0\" class=\"row_heading level0 row0\" >8</th>\n","                        <td id=\"T_22b2b024_12f2_11eb_8446_0242ac1c0002row0_col0\" class=\"data row0 col0\" >비례대표 후보만을 낸 이른바 비례 정당들의 선거운동의 열기가 뜨겁다. 비례 정당들은 지역구 정당과의 연관성을 부각하기 위해 각종 꼼수도 활용하고 있다. 주로 비례 정당 후보가 손가락으로 자신이 속한 정당의 기호와 지역구 정당 후보의 기호를 함께 표시하면서 ‘자매 정당’인 점을 강조하고 있다. 지역구 정당과 비례 정당 후보들이 서로 도와서 유세를 할 때 종종 목격되는 모습인데, 더불어민주당과 더불어시민당은 각 당의 기호인 숫자 1과 5를, 미래통합당과 미래한국당은 2와 4를 함께 홍보하는 식이다. 선거법에 저촉되는 것은 아닌지 따져봤다.</td>\n","                        <td id=\"T_22b2b024_12f2_11eb_8446_0242ac1c0002row0_col1\" class=\"data row0 col1\" >0.389521</td>\n","                        <td id=\"T_22b2b024_12f2_11eb_8446_0242ac1c0002row0_col2\" class=\"data row0 col2\" >0</td>\n","                        <td id=\"T_22b2b024_12f2_11eb_8446_0242ac1c0002row0_col3\" class=\"data row0 col3\" >1</td>\n","            </tr>\n","            <tr>\n","                        <th id=\"T_22b2b024_12f2_11eb_8446_0242ac1c0002level0_row1\" class=\"row_heading level0 row1\" >12</th>\n","                        <td id=\"T_22b2b024_12f2_11eb_8446_0242ac1c0002row1_col0\" class=\"data row1 col0\" >-  이달 초 교육부는 '대학생 주류 판매 관련 주세법령 준수 안내 협조'라는 제목의 공문을 각 대학교에 발송했습니다.  -  공문에는 대학생들이 학교축제 기간 주류 판매업 면허 없이 주점을 운영하는 등 주세법을 위반하는 사례가 매년 발생하고, 이들이 무면허로 술을 팔면 처벌된다는 내용이 담겨 있습니다.-  하지만 5월에만 30개 가까운 대학교에 축제가 열리며, 많은 대학생들은 큰 위법 인식 없이 노상에서 주류 판매하고 있습니다.-  대학생이 축제에서 무면허로 술을 팔면 진짜 처벌을 받게 되는 건지 확인해 봅니다.</td>\n","                        <td id=\"T_22b2b024_12f2_11eb_8446_0242ac1c0002row1_col1\" class=\"data row1 col1\" >0.655225</td>\n","                        <td id=\"T_22b2b024_12f2_11eb_8446_0242ac1c0002row1_col2\" class=\"data row1 col2\" >1</td>\n","                        <td id=\"T_22b2b024_12f2_11eb_8446_0242ac1c0002row1_col3\" class=\"data row1 col3\" >0</td>\n","            </tr>\n","            <tr>\n","                        <th id=\"T_22b2b024_12f2_11eb_8446_0242ac1c0002level0_row2\" class=\"row_heading level0 row2\" >13</th>\n","                        <td id=\"T_22b2b024_12f2_11eb_8446_0242ac1c0002row2_col0\" class=\"data row2 col0\" >코로나19에 대한 공포감이 높아지고 대면 접촉이 어려워지자 총선 후보들이 약통을 메고 거리에 소독약을 뿌리고 있다. 자치단체장들은 지역 군부대와 협조해 화학부대를 동원해 거리 소독에 나섰다.박원순 서울시장은 지난달 24일 긴급 서울시 안전관리위원회를 개최하고 수도방위사령부의 협력을 요청했다. 이에 수도방위사령부는 제독차량12대와 병력 411명을 긴급 투입했다. 서울시는 “각 지자체의 요청이 들어오는 대로 다수의 인원이 모이는 장소를 중심으로 소독을 실시할 계획”이라고 밝혔다. 지난 4일 장병들은 은평구 일대에서 제독차 방역을 실시했다. 감염이 확산된 대구 경북은 물론 강원, 광주 등 전국 각지에서 군 제독차가 동원돼 거리 소독에 나섰다. 보수와 진보를 불문하고 선거철을 맞은 정치인들도 방역활동을 하러 거리로 나섰다. 황교안 미래통합당 대표는 지난달 25일부터 종로구 거리 방역에 나섰다. 약통을 둘러메고 분무기로 거리에 소독약을 뿌리며 유권자를 만나고 있다. 공중화장실에 소독약을 뿌리</td>\n","                        <td id=\"T_22b2b024_12f2_11eb_8446_0242ac1c0002row2_col1\" class=\"data row2 col1\" >0.815403</td>\n","                        <td id=\"T_22b2b024_12f2_11eb_8446_0242ac1c0002row2_col2\" class=\"data row2 col2\" >1</td>\n","                        <td id=\"T_22b2b024_12f2_11eb_8446_0242ac1c0002row2_col3\" class=\"data row2 col3\" >0</td>\n","            </tr>\n","            <tr>\n","                        <th id=\"T_22b2b024_12f2_11eb_8446_0242ac1c0002level0_row3\" class=\"row_heading level0 row3\" >17</th>\n","                        <td id=\"T_22b2b024_12f2_11eb_8446_0242ac1c0002row3_col0\" class=\"data row3 col0\" >신종 코로나바이러스 감염증(코로나19) 확진 판정을 받은 도널드 트럼프 미 대통령이 자신의 SNS에 “코로나는 독감보다 덜 치명적이다”라고 주장해 논란이 일고 있다. 6일(현지시간) 트럼프 대통령은 자신의 트위터에 “백신이 있어도 매년 10만명 이상이 독감으로 사망하고 있다”며 “우리는 코로나와 함께 사는 법을 배우는 것처럼, 대부분 사람들에게 훨씬 덜 치명적이다”라고 적었다.</td>\n","                        <td id=\"T_22b2b024_12f2_11eb_8446_0242ac1c0002row3_col1\" class=\"data row3 col1\" >0.083245</td>\n","                        <td id=\"T_22b2b024_12f2_11eb_8446_0242ac1c0002row3_col2\" class=\"data row3 col2\" >0</td>\n","                        <td id=\"T_22b2b024_12f2_11eb_8446_0242ac1c0002row3_col3\" class=\"data row3 col3\" >1</td>\n","            </tr>\n","    </tbody></table>"],"text/plain":["<pandas.io.formats.style.Styler at 0x7f0cf00b79b0>"]},"metadata":{"tags":[]},"execution_count":116}]},{"cell_type":"code","metadata":{"id":"14Xs2UmSHSuu","executionInfo":{"status":"ok","timestamp":1603211674383,"user_tz":-540,"elapsed":651286,"user":{"displayName":"도리","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GigxDhsmqwbOX_7DzSWfaZBxGNeTsT52f8kX_3Y=s64","userId":"14668422416762760759"}}},"source":["from keras.preprocessing.sequence import pad_sequences"],"execution_count":117,"outputs":[]},{"cell_type":"code","metadata":{"id":"G7Epul5qEd-P","executionInfo":{"status":"ok","timestamp":1603211674384,"user_tz":-540,"elapsed":651284,"user":{"displayName":"도리","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GigxDhsmqwbOX_7DzSWfaZBxGNeTsT52f8kX_3Y=s64","userId":"14668422416762760759"}}},"source":["tokenized_df = []\n","\n","def prePro(sentence):\n","  sentence = tokenizer.tokenize(str(sentence))[:510]\n","  tokenized_df = \"[CLS]\" + str(sentence) + \"[SEP]\"\n","\n","  totalpadlength = 512\n","\n","  indexed_tokens = [tokenizer.convert_tokens_to_ids(tokenized_df)]\n","  index_padded = pad_sequences(indexed_tokens, maxlen=totalpadlength, dtype=\"long\", truncating=\"post\", padding=\"post\")\n","\n","  attention_masks=[]\n","\n","  for seq in index_padded:\n","        mask_variable = [float(i>0) for i in seq]\n","        attention_masks.append(mask_variable)\n","\n","  index_padded = torch.tensor(index_padded)\n","  attention_masks = torch.tensor(attention_masks)\n","  \n","  logit, hidden = sentenceTest(model, index_padded, attention_masks, device)\n","\n","  return logit, hidden, tokenized_df"],"execution_count":118,"outputs":[]},{"cell_type":"code","metadata":{"id":"K6d0anrGE1o4","executionInfo":{"status":"ok","timestamp":1603211674385,"user_tz":-540,"elapsed":651283,"user":{"displayName":"도리","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GigxDhsmqwbOX_7DzSWfaZBxGNeTsT52f8kX_3Y=s64","userId":"14668422416762760759"}}},"source":["def sentenceTest(model, index_padded, mask_variable,  device):\n","    tqdm()\n","    model.eval()\n","\n","    token_ids = index_padded.to(device)\n","    masks = mask_variable.to(device)\n","\n","    with torch.no_grad():\n","        logit, hidden = model(input_ids=token_ids, attention_mask=masks)\n","\n","    return logit, hidden"],"execution_count":119,"outputs":[]},{"cell_type":"code","metadata":{"id":"fZB8CQnFFLB5","executionInfo":{"status":"error","timestamp":1603211674693,"user_tz":-540,"elapsed":651579,"user":{"displayName":"도리","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GigxDhsmqwbOX_7DzSWfaZBxGNeTsT52f8kX_3Y=s64","userId":"14668422416762760759"}},"outputId":"f3ac787c-3354-47bf-c256-8194cc5de94c","colab":{"base_uri":"https://localhost:8080/","height":448}},"source":["logic, hidden, tokenized_df = prePro([''])"],"execution_count":120,"outputs":[{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras_preprocessing/sequence.py\u001b[0m in \u001b[0;36mpad_sequences\u001b[0;34m(sequences, maxlen, dtype, padding, truncating, value)\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m             \u001b[0mlengths\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mflag\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: object of type 'int' has no len()","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-120-592fab4358d8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlogic\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenized_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprePro\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-118-d3a5f1a8e39d>\u001b[0m in \u001b[0;36mprePro\u001b[0;34m(sentence)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m   \u001b[0mindexed_tokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_tokens_to_ids\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenized_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m   \u001b[0mindex_padded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpad_sequences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexed_tokens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxlen\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtotalpadlength\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"long\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtruncating\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"post\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"post\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m   \u001b[0mattention_masks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/preprocessing/sequence.py\u001b[0m in \u001b[0;36mpad_sequences\u001b[0;34m(sequences, maxlen, dtype, padding, truncating, value)\u001b[0m\n\u001b[1;32m    156\u001b[0m   return sequence.pad_sequences(\n\u001b[1;32m    157\u001b[0m       \u001b[0msequences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxlen\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmaxlen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 158\u001b[0;31m       padding=padding, truncating=truncating, value=value)\n\u001b[0m\u001b[1;32m    159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m keras_export(\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras_preprocessing/sequence.py\u001b[0m in \u001b[0;36mpad_sequences\u001b[0;34m(sequences, maxlen, dtype, padding, truncating, value)\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m             raise ValueError('`sequences` must be a list of iterables. '\n\u001b[0;32m---> 74\u001b[0;31m                              'Found non-iterable: ' + str(x))\n\u001b[0m\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmaxlen\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: `sequences` must be a list of iterables. Found non-iterable: 100"]}]},{"cell_type":"code","metadata":{"id":"4MH20a_9OODt","executionInfo":{"status":"aborted","timestamp":1603211674686,"user_tz":-540,"elapsed":651552,"user":{"displayName":"도리","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GigxDhsmqwbOX_7DzSWfaZBxGNeTsT52f8kX_3Y=s64","userId":"14668422416762760759"}}},"source":["print(logit)\n","print(np.argmax(logit.detach().cpu().numpy()))\n","\n","label = np.argmax(logit.detach().cpu().numpy())"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"JfLqQLARK-EL","executionInfo":{"status":"aborted","timestamp":1603211674687,"user_tz":-540,"elapsed":651551,"user":{"displayName":"도리","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GigxDhsmqwbOX_7DzSWfaZBxGNeTsT52f8kX_3Y=s64","userId":"14668422416762760759"}}},"source":["token_embeddings = torch.stack(hidden, dim=0)\n","token_embeddings = torch.squeeze(token_embeddings, dim=1)\n","token_embeddings = token_embeddings.permute(1,0,2)\n","\n","token_embeddings.size()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7_JMbsb2LKEp","executionInfo":{"status":"aborted","timestamp":1603211674687,"user_tz":-540,"elapsed":651548,"user":{"displayName":"도리","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GigxDhsmqwbOX_7DzSWfaZBxGNeTsT52f8kX_3Y=s64","userId":"14668422416762760759"}}},"source":["token_vecs_sum = []\n","\n","for token in token_embeddings:\n","    sum_vec = torch.sum(token[-4:], dim=0)\n","    token_vecs_sum.append(sum_vec)\n","\n","print ('Shape is: %d x %d' % (len(token_vecs_sum), len(token_vecs_sum[0])))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"R3fUKCB8LOBS","executionInfo":{"status":"aborted","timestamp":1603211674688,"user_tz":-540,"elapsed":651546,"user":{"displayName":"도리","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GigxDhsmqwbOX_7DzSWfaZBxGNeTsT52f8kX_3Y=s64","userId":"14668422416762760759"}}},"source":["from scipy.spatial.distance import cosine\n","import matplotlib.pyplot as plt\n","\n","clsCosine = []\n","\n","for i, vec in enumerate(token_vecs_sum):\n","    if i == 509:\n","      break\n","    pooler = 1 - cosine(token_vecs_sum[0].detach().cpu().numpy(), vec.detach().cpu().numpy())\n","    print('[CLS] vs ',tokenized_df[i],' :  %f' % pooler)\n","    clsCosine.append(pooler)\n","    \n","\n","plt.figure(figsize = (12,4)) \n","plt.plot(clsCosine) \n","plt.ylim(0,1.2)\n","\n","plt.legend();"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Sfp8FYEgPc9s","executionInfo":{"status":"aborted","timestamp":1603211674688,"user_tz":-540,"elapsed":651544,"user":{"displayName":"도리","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GigxDhsmqwbOX_7DzSWfaZBxGNeTsT52f8kX_3Y=s64","userId":"14668422416762760759"}}},"source":["plt.figure(figsize = (12,4)) \n","plt.plot(token_vecs_sum[0][:100].detach().cpu().numpy(), linewidth=3)\n","plt.plot(token_vecs_sum[1][:100].detach().cpu().numpy())\n","plt.plot(token_vecs_sum[2][:100].detach().cpu().numpy())\n","plt.plot(token_vecs_sum[3][:100].detach().cpu().numpy())\n","plt.plot(token_vecs_sum[4][:100].detach().cpu().numpy())\n","\n","plt.ylim(-10,10)\n","\n","plt.legend();"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Sg39dBxUWNUZ","executionInfo":{"status":"aborted","timestamp":1603211674689,"user_tz":-540,"elapsed":651538,"user":{"displayName":"도리","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GigxDhsmqwbOX_7DzSWfaZBxGNeTsT52f8kX_3Y=s64","userId":"14668422416762760759"}}},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dwoSJZSFR_iW","executionInfo":{"status":"aborted","timestamp":1603211674689,"user_tz":-540,"elapsed":651533,"user":{"displayName":"도리","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GigxDhsmqwbOX_7DzSWfaZBxGNeTsT52f8kX_3Y=s64","userId":"14668422416762760759"}}},"source":["import tensorflow as tf\n","import numpy as np\n","from IPython.core.display import HTML, display\n","\n","m = torch.nn.Linear(768, 2, bias=True).to(device)\n","m.weight.data = model.classifier.weight.to(device)\n","\n","n = torch.nn.ReLU()\n","d = torch.nn.Dropout(p=0.1, inplace=False)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"FBeobEVkSiEq","executionInfo":{"status":"aborted","timestamp":1603211674690,"user_tz":-540,"elapsed":651531,"user":{"displayName":"도리","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GigxDhsmqwbOX_7DzSWfaZBxGNeTsT52f8kX_3Y=s64","userId":"14668422416762760759"}}},"source":["result=[]\n","\n","with torch.no_grad():\n","  def call_html(i, output, token_str, label):\n","    # color = str(int(round(output*1000)))\n","\n","    fake = \"<script type='text/javascript'> var span = document.createElement('span'); var newContent = document.createTextNode('\"+token_str+\" '); span.appendChild(newContent); span.style.color='rgb(\"+str(output*255)+\",0,0)'; document.body.appendChild(span); </script>\"\n","    real = \"<script type='text/javascript'> var span = document.createElement('span'); var newContent = document.createTextNode('\"+token_str+\" '); span.appendChild(newContent); span.style.color='rgb(0,\"+str(output*255)+\",0)'; document.body.appendChild(span); </script>\"\n","\n","    if label == 0:\n","      display(HTML(fake))\n","    else:\n","      display(HTML(real))\n","    \n","  def vis(i, token_str, label):\n","    output = round(clsCosine[i], 3)\n","    # output = token_vecs_sum[i]\n","    # output = output.to(device)\n","    # output = m(output)\n","    # result.append(output)\n","    # result_output = torch.cat(result, dim=0)    \n","    # output = n(output)\n","    # output = output.detach().cpu().numpy()\n","    # output= np.max(output[label])\n","    call_html(i, output, token_str, label)\n","\n","    # return result_output"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"GL9nCPhBUjOB","executionInfo":{"status":"aborted","timestamp":1603211674690,"user_tz":-540,"elapsed":651529,"user":{"displayName":"도리","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GigxDhsmqwbOX_7DzSWfaZBxGNeTsT52f8kX_3Y=s64","userId":"14668422416762760759"}}},"source":["for i, token_str in enumerate(tokenized_df):\n","  if token_str == \"[CLS]\" or token_str == \"[SEP]\"  :\n","    continue \n","    \n","  histogram = vis(i, token_str, label)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4LmzbrFwYemF","executionInfo":{"status":"aborted","timestamp":1603211674690,"user_tz":-540,"elapsed":651526,"user":{"displayName":"도리","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GigxDhsmqwbOX_7DzSWfaZBxGNeTsT52f8kX_3Y=s64","userId":"14668422416762760759"}}},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"FspMJU2pnYUW","executionInfo":{"status":"aborted","timestamp":1603211674691,"user_tz":-540,"elapsed":651522,"user":{"displayName":"도리","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GigxDhsmqwbOX_7DzSWfaZBxGNeTsT52f8kX_3Y=s64","userId":"14668422416762760759"}}},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"e2P0ycKHpJNf","executionInfo":{"status":"aborted","timestamp":1603211674691,"user_tz":-540,"elapsed":651519,"user":{"displayName":"도리","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GigxDhsmqwbOX_7DzSWfaZBxGNeTsT52f8kX_3Y=s64","userId":"14668422416762760759"}}},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"R0HZu9viquFe","executionInfo":{"status":"aborted","timestamp":1603211674692,"user_tz":-540,"elapsed":651518,"user":{"displayName":"도리","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GigxDhsmqwbOX_7DzSWfaZBxGNeTsT52f8kX_3Y=s64","userId":"14668422416762760759"}}},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3v93Ksy5reA4","executionInfo":{"status":"aborted","timestamp":1603211674692,"user_tz":-540,"elapsed":651515,"user":{"displayName":"도리","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GigxDhsmqwbOX_7DzSWfaZBxGNeTsT52f8kX_3Y=s64","userId":"14668422416762760759"}}},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZGhkbguksWC1","executionInfo":{"status":"aborted","timestamp":1603211674692,"user_tz":-540,"elapsed":651513,"user":{"displayName":"도리","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GigxDhsmqwbOX_7DzSWfaZBxGNeTsT52f8kX_3Y=s64","userId":"14668422416762760759"}}},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_74wSvo7s2TO","executionInfo":{"status":"aborted","timestamp":1603211674693,"user_tz":-540,"elapsed":651511,"user":{"displayName":"도리","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GigxDhsmqwbOX_7DzSWfaZBxGNeTsT52f8kX_3Y=s64","userId":"14668422416762760759"}}},"source":[""],"execution_count":null,"outputs":[]}]}